import streamlit as st
from AdaptiveRAG import AdaptiveAgent
from pathlib import Path
from dotenv import load_dotenv
from QueryTransformation import QueryTransformation
# Load environment variables
load_dotenv(Path("./.env"))

from langchain_community.callbacks.streamlit import StreamlitCallbackHandler
from langchain_community.chat_message_histories import StreamlitChatMessageHistory
from agentGemi import get_llm_and_agent
import warnings
warnings.filterwarnings("ignore")  # Chá»‰ táº¯t FutureWarning


# === THIáº¾T Láº¬P GIAO DIá»†N TRANG WEB ===-+
def setup_page():
    """
    Cáº¥u hÃ¬nh trang web cÆ¡ báº£n
    """

    # Cáº¥u hÃ¬nh giao diá»‡n trang
    st.set_page_config(
        page_title="University Admission Assistant",    # TiÃªu Ä‘á» tab trÃ¬nh duyá»‡t
        page_icon="ğŸ“",                                # Icon tab
        layout="wide"
    )

# === KHá»I Táº O á»¨NG Dá»¤NG ===
def initialize_app():
    """
    Khá»Ÿi táº¡o cÃ¡c cÃ i Ä‘áº·t cáº§n thiáº¿t:
    - Äá»c file .env chá»©a API key
    - Cáº¥u hÃ¬nh trang web
    """
    load_dotenv(Path("./.env"))  # Äá»c API key tá»« file .env
    setup_page()  # Thiáº¿t láº­p giao diá»‡n

def show_contact():
    """
    Hiá»ƒn thá»‹ thÃ´ng tin liÃªn há»‡
    """
    st.write("""
        Náº¿u báº¡n cÃ³ báº¥t ká»³ cÃ¢u há»i nÃ o hoáº·c cáº§n há»— trá»£ thÃªm, Ä‘á»«ng ngáº§n ngáº¡i liÃªn há»‡ vá»›i tÃ´i qua:
    """)
    st.write("ğŸ“§ **Email**: your_email@example.com")
    st.write("ğŸ“± **Phone**: +123 456 789")
    st.write("ğŸŒ **Website**: [yourwebsite.com](https://www.yourwebsite.com)")
    st.write("ğŸ”— **LinkedIn**: [Your LinkedIn](https://www.linkedin.com/in/yourprofile)")

# === THANH CÃ”NG Cá»¤ BÃŠN TRÃI ===
def setup_sidebar():
    """
    Táº¡o thanh cÃ´ng cá»¥ bÃªn trÃ¡i vá»›i cÃ¡c tÃ¹y chá»n
    """
    with st.sidebar:
        st.title("âš™ï¸ Cáº¥u hÃ¬nh")
        # Pháº§n 1: Introduce
        st.header("ğŸ“ Trá»£ LÃ½ Tuyá»ƒn Sinh Äáº¡i Há»c")
        st.markdown(
            """
            Há»‡ thá»‘ng há»— trá»£ tra cá»©u thÃ´ng tin tuyá»ƒn sinh cá»§a cÃ¡c trÆ°á»ng Ä‘áº¡i há»c táº¡i TP.HCM:
            - Äáº¡i há»c Nguyá»…n Táº¥t ThÃ nh (NTTU)
            - Äáº¡i há»c SÆ° Pháº¡m TP.HCM (HCMUE)
            - Äáº¡i há»c Y DÆ°á»£c TP.HCM (UPM)
            - Äáº¡i há»c SÆ° Pháº¡m Ká»¹ Thuáº­t TP.HCM (HCMUTE)
            - Äáº¡i há»c VÄƒn Lang (VLU)
            - VÃ  cÃ¡c trÆ°á»ng khÃ¡c...
            """
        )
        # ThÃªm nÃºt "New Chat"
        if st.button("ğŸ†• New Chat"):
            # Reset lá»‹ch sá»­ tin nháº¯n
            st.session_state.messages = [
                {"role": "assistant", "content": "TÃ´i cÃ³ thá»ƒ giÃºp gÃ¬ cho báº¡n?"}
            ]
            st.success("Cuá»™c trÃ² chuyá»‡n má»›i Ä‘Ã£ Ä‘Æ°á»£c táº¡o!")
            
        
        # Pháº§n 1: Chá»n Model Ä‘á»ƒ tráº£ lá»i
        st.header("ğŸ¤– Model AI")
        model_choice = st.radio(
            "Chá»n AI Model Ä‘á»ƒ tráº£ lá»i:",
            ["Geminai", "OpenAI GPT-4", "OpenAI Grok", "Ollama (Local)"]
        )

        
        return model_choice


# === GIAO DIá»†N CHAT CHÃNH ===
def setup_chat_interface(model_choice):
    st.title("ğŸ’¬ AI Assistant")
    
    # Caption Ä‘á»™ng theo model
    if model_choice == "OpenAI GPT-4":
        st.caption("ğŸš€ Trá»£ lÃ½ AI Ä‘Æ°á»£c há»— trá»£ bá»Ÿi LangChain vÃ  OpenAI GPT-4")
    elif model_choice == "OpenAI Grok":
        st.caption("ğŸš€ Trá»£ lÃ½ AI Ä‘Æ°á»£c há»— trá»£ bá»Ÿi LangChain vÃ  X.AI Grok")
        
    elif model_choice == "OpenAI Grok":
        st.caption("ğŸš€ Trá»£ lÃ½ AI Ä‘Æ°á»£c há»— trá»£ bá»Ÿi LangChain vÃ  X.AI Grok")
    else:
        st.caption("ğŸš€ Trá»£ lÃ½ AI Ä‘Æ°á»£c há»— trá»£ bá»Ÿi LangChain vÃ  Ollama LLaMA2")
    
    msgs = StreamlitChatMessageHistory(key="langchain_messages")
    
    if "messages" not in st.session_state:
        st.session_state.messages = [
            {"role": "assistant", "content": "TÃ´i cÃ³ thá»ƒ giÃºp gÃ¬ cho báº¡n?"}
        ]
        msgs.add_ai_message("TÃ´i cÃ³ thá»ƒ giÃºp gÃ¬ cho báº¡n?")

    for msg in st.session_state.messages:
        role = "assistant" if msg["role"] == "assistant" else "human"
        st.chat_message(role).write(msg["content"])
        
    return msgs


# === Xá»¬ LÃ TIN NHáº®N NGÆ¯á»œI DÃ™NG ===
def handle_user_input(prompt, msgs, agent_executor):
    """
    Xá»­ lÃ½ khi ngÆ°á»i dÃ¹ng gá»­i tin nháº¯n:
    1. Hiá»ƒn thá»‹ tin nháº¯n ngÆ°á»i dÃ¹ng
    2. Gá»i AI xá»­ lÃ½ vÃ  tráº£ lá»i
    3. LÆ°u vÃ o lá»‹ch sá»­ chat
    """
    
    
    st.session_state.messages.append({"role": "human", "content": prompt})
    st.chat_message("human").write(prompt)
    msgs.add_user_message(prompt)

    # Xá»­ lÃ½ vÃ  hiá»ƒn thá»‹ cÃ¢u tráº£ lá»i
    with st.chat_message("assistant"):
        st_callback = StreamlitCallbackHandler(st.container())
        
        # Láº¥y lá»‹ch sá»­ chat
        chat_history = [
            {"role": msg["role"], "content": msg["content"]}
            for msg in st.session_state.messages[:-1]
        ]

        # Gá»i AI xá»­ lÃ½
        response = agent_executor.invoke(
            {
                "input": prompt,
                "chat_history": chat_history
            },
            {"callbacks": [st_callback]}
        )

        # LÆ°u vÃ  hiá»ƒn thá»‹ cÃ¢u tráº£ lá»i
        output = response["output"]
        st.session_state.messages.append({"role": "assistant", "content": output})
        msgs.add_ai_message(output)
        st.write(output)

# === Xá»¬ LÃ TIN NHáº®N NGÆ¯á»œI DÃ™NG ===

# === HÃ€M CHÃNH ===
def main():
    """
    HÃ m chÃ­nh Ä‘iá»u khiá»ƒn luá»“ng chÆ°Æ¡ng trÃ¬nh
    """
    
    initialize_app()
    prompt = st.chat_input("HÃ£y há»i tÃ´i báº¥t cá»© Ä‘iá»u gÃ¬ vá» thÃ´n tin tuyá»ƒn sinh")
    tab1, tab2= st.tabs(["Chat", "Contact"])
    # agent_executor = None  # Äáº£m báº£o biáº¿n Ä‘Æ°á»£c khá»Ÿi táº¡o
    
    
    with tab1:
        model_choice= setup_sidebar()
        msgs = setup_chat_interface(model_choice)
        
        # Khá»Ÿi táº¡o AI dá»±a trÃªn lá»±a chá»n model Ä‘á»ƒ tráº£ lá»i
        
        # if model_choice == "OpenAI GPT-4":
        #     retriever = get_openai_retriever(collection_to_query)
        #     agent_executor = get_openai_agent(retriever, "gpt4")
        # elif model_choice == "OpenAI Grok":
        #     retriever = get_openai_retriever(collection_to_query)
        #     agent_executor = get_openai_agent(retriever, "grok")
        if model_choice == "Geminai":
            agent_executor = get_llm_and_agent()
            
        # else:
        #     retriever = get_ollama_retriever(collection_to_query)
        #     agent_executor = get_ollama_agent(retriever)

        if prompt:
            handle_user_input(prompt, msgs, agent_executor)

    with tab2:
        
        show_contact()

# Cháº¡y á»©ng dá»¥ng
if __name__ == "__main__":
    main() 